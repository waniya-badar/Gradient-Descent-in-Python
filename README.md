# Gradient-Descent-in-Python
Gradient Descent- An optimization algorithm written in Python that minimizes a function by iteratively moving in the direction of the steepest descent, as determined by the negative gradient. It is commonly used in machine learning to update model parameters and find the function's minimum value. This is displayed through 3D and scatter plots.
